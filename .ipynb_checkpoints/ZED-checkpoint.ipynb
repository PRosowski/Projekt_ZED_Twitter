{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "train= pd.read_csv(\"train.csv\", sep=\",\")\n",
    "test = pd.read_csv(\"test.csv\", sep=\",\")\n",
    "\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "happy = set([\n",
    "    u':-)', u':)', u';)', u':o)', u':]', u':3', u':c)', u':>', u'=]', u'8)', u'=)', u':}',\n",
    "    u':^)', u':-D', u':D', u'8-D', u'8D', u'x-D', u'xD', u'X-D', u'XD', u'=-D', u'=D',\n",
    "    u'=-3', u'=3', u':-))', u\":'-)\", u\":')\", u':*', u':^*', u'>:P', u':-P', u':P', u'X-P',\n",
    "    u'x-p', u'xp', u'XP', u':-p', u':p', u'=p', u':-b', u':b', u'>:)', u'>;)', u'>:-)',\n",
    "    u'<3', u'8-)'\n",
    "    ])\n",
    "\n",
    "sad = set([\n",
    "    u':L', u':-/', u'>:/', u':S', u'>:[', u':@', u':-(', u':[', u':-||', u'=L', u':<',\n",
    "    u':-[', u':-<', u'=\\\\', u'=/', u'>:(', u':(', u'>.<', u\":'-(\", u\":'(\", u':\\\\', u':-c',\n",
    "    u':c', u':{', u'>:\\\\', u';('\n",
    "    ])\n",
    "\n",
    "def tokenize( raw_tweet ):\n",
    "    words = raw_tweet.lower().split()   \n",
    "    words = [w for w in words if not w in stopwords]\n",
    "    for one_sentence in words:    \n",
    "        if one_sentence in sad:\n",
    "            words[words.index(one_sentence)] = 'bad fuck sad'\n",
    "        elif one_sentence in happy:\n",
    "            words[words.index(one_sentence)] = 'happi great happy'\n",
    "        elif re.match(r'^https?:\\/\\/.*[\\r\\n]*',one_sentence):\n",
    "            words[words.index(one_sentence)] = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', one_sentence, flags=re.MULTILINE)\n",
    "        elif re.match(r'(?:@[\\w_]+)',one_sentence):\n",
    "            words[words.index(one_sentence)] = re.sub(r'(?:@[\\w_]+)', '', one_sentence)\n",
    "        elif re.match(r'\\d+', one_sentence):\n",
    "            words[words.index(one_sentence)]  = ''\n",
    "        else:\n",
    "            words[words.index(one_sentence)] = re.sub(r'[^\\w\\s]','',one_sentence)\n",
    "        \n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    return( \" \".join( words ))\n",
    "\n",
    "clean_train_tweets = []\n",
    "\n",
    "for index, data in train.iterrows():\n",
    "    clean_train_tweets.append(tokenize(data['Tweet']))\n",
    "\n",
    "    \n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None,    \n",
    "                             preprocessor = None,stop_words = None,   \n",
    "                             max_features = 5000,min_df = 10,max_df = 0.80) \n",
    "    \n",
    " \n",
    "train_features = vectorizer.fit_transform(clean_train_tweets)\n",
    "train_features = train_features.toarray()\n",
    "\n",
    "\n",
    "clean_test_tweets = [] \n",
    "\n",
    "for index, data in test.iterrows():\n",
    "    clean_test_tweets.append(tokenize(data['Category']))\n",
    "\n",
    "\n",
    "\n",
    "test_features = vectorizer.transform(clean_test_tweets)\n",
    "test_features = test_features.toarray()\n",
    "\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "forest = forest.fit( train_features, train[\"Category\"] )\n",
    "forest = forest.predict(test_features)\n",
    "\n",
    "\n",
    "output = pd.DataFrame(data={\"Id\": test[\"Id\"], \"Category\": forest})\n",
    "output = output.sort_index(axis=1, ascending=False)\n",
    "\n",
    "output.to_csv( \"submission.csv\", index=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
